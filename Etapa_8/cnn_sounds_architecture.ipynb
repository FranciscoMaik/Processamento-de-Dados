{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S03 T02: CNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The one with the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import utils\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The one who prepare the CNN input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(name):\n",
    "    with (open(name, 'rb')) as openfile:\n",
    "        while True:\n",
    "            try:\n",
    "                one_instance = pickle.load(openfile)\n",
    "            except EOFError:\n",
    "                break\n",
    "    one_instance = np.asanyarray(one_instance)\n",
    "    return one_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = read_pickle('x_train.pickle')\n",
    "y_train = read_pickle('y_train.pickle')\n",
    "x_test = read_pickle('x_test.pickle')\n",
    "y_test = read_pickle('y_test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2649, 173, 173)\n",
      "(2649,)\n",
      "(10901, 173, 173)\n",
      "(10901,)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing_data_to_keras_format(x, y):\n",
    "    x = x.reshape(x.shape[0],x.shape[1],x.shape[2],1)\n",
    "    y = utils.to_categorical(y) #8 -> 0 0 0 0 0 0 0 0 1 0\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redimensionando os espectogramas e labels\n",
    "x_train, y_train = pre_processing_data_to_keras_format(x_train, y_train)\n",
    "x_test, y_test = pre_processing_data_to_keras_format(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2649, 173, 173, 1)\n",
      "(2649, 10)\n",
      "(10901, 173, 173, 1)\n",
      "(10901, 10)\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The one with the network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parâmetros de modelo\n",
    "dropout_value = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The one with the network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializando a CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "#Camada de convolução\n",
    "classifier.add(Convolution2D(32, kernel_size=(5,5), input_shape = (173, 173,1), activation = 'relu', padding='same', name = 'conv_1'))\n",
    "\n",
    "#Camada de pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2), padding='same', name = 'pool_1'))\n",
    "\n",
    "#Camada de normalização\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#Segunda camada convolucional\n",
    "classifier.add(Convolution2D(64, kernel_size=(5,5), activation = 'relu', padding='same', name = 'conv_2'))\n",
    "\n",
    "#Segunda camada de pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name = 'pool_2'))\n",
    "\n",
    "#Segunda camada de normalização\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#Terceira camada convolucional\n",
    "classifier.add(Convolution2D(64, kernel_size=(5,5), activation = 'relu', padding='same', name = 'conv_3'))\n",
    "\n",
    "#Terceira camada de pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name = 'pool_3'))\n",
    "\n",
    "#Terceira camada de normalização\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#Quarta camada convolucional\n",
    "classifier.add(Convolution2D(64, kernel_size=(5,5), activation = 'relu', padding='same', name = 'conv_4'))\n",
    "\n",
    "#Quarta camada de pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name = 'pool_4'))\n",
    "\n",
    "#Quarta camada de normalização\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#Vetorizando os mapas de características do último pooling (camada de entrada)\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#Dropout\n",
    "classifier.add(Dropout(dropout_value))\n",
    "\n",
    "#Camada totalmente conectada ou oculta\n",
    "classifier.add(Dense(activation='relu', units=256, name = 'dense_1'))\n",
    "\n",
    "#Dropout\n",
    "classifier.add(Dropout(dropout_value))\n",
    "\n",
    "#Camada de saída\n",
    "classifier.add(Dense(activation='softmax', units=10,  name = 'classification'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 173, 173, 32)      832       \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        (None, 87, 87, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 87, 87, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 87, 87, 64)        51264     \n",
      "_________________________________________________________________\n",
      "pool_2 (MaxPooling2D)        (None, 44, 44, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 44, 44, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 44, 44, 64)        102464    \n",
      "_________________________________________________________________\n",
      "pool_3 (MaxPooling2D)        (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 22, 22, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 22, 22, 64)        102464    \n",
      "_________________________________________________________________\n",
      "pool_4 (MaxPooling2D)        (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 11, 11, 64)        256       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1982720   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "classification (Dense)       (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,243,210\n",
      "Trainable params: 2,242,762\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Atividade (2.0 pt):$ apresentar um notebook com a arquitetura adaptada para os spectrograms da sua base."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
