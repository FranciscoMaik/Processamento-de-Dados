{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"cnn_sounds_architecture_training.ipynb","provenance":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"34s2wuVzKJyg"},"source":["# S03 T02: CNN Architecture"]},{"cell_type":"markdown","metadata":{"id":"SQBPmogMKJym"},"source":["## The one with the libraries"]},{"cell_type":"code","metadata":{"id":"Z6lZJQIPKJyq"},"source":["from keras.models import Sequential\n","from keras.layers import Convolution2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Flatten\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import BatchNormalization\n","from keras import utils\n","import pickle\n","import numpy as np\n","from keras import models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"brpaV1mNKJzD"},"source":["path_save = \"/content/drive/My Drive/Piclkes Mel Spec/Aquivos H5/\"\n","path = \"/content/drive/My Drive/Piclkes Mel Spec/Com aumentation/\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DMtviFeuKJzS"},"source":["## The one who prepare the CNN input "]},{"cell_type":"code","metadata":{"id":"iVuKXBlhKJzX"},"source":["def read_pickle(name):\n","    with (open(name, 'rb')) as openfile:\n","        while True:\n","            try:\n","                one_instance = pickle.load(openfile)\n","            except EOFError:\n","                break\n","    one_instance = np.asanyarray(one_instance)\n","    return one_instance"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"peErn0F-KJzk"},"source":["x_train = read_pickle(path+'Treino_x_Treino_mel_aug.pickle')\n","y_train = read_pickle(path+'Treino_y_Treino_mel_aug.pickle')\n","x_test = read_pickle(path+'Teste_x_Teste_mel.pickle')\n","y_test = read_pickle(path+'Teste_y_Teste_mel_int.pickle')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v3eOVv-FKJzv","executionInfo":{"status":"ok","timestamp":1600533071071,"user_tz":180,"elapsed":1606,"user":{"displayName":"Maik Fonseca","photoUrl":"","userId":"00360461244938649347"}},"outputId":"0ea77cc1-bf71-4be1-8131-c3cbfdbc8bf2","colab":{"base_uri":"https://localhost:8080/","height":86}},"source":["print(x_test.shape)\n","print(y_test.shape)\n","print(x_train.shape)\n","print(y_train.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(4001, 201, 201)\n","(4001,)\n","(23211, 201, 201)\n","(23211,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I0BVV0R6KJ0A"},"source":["def pre_processing_data_to_keras_format(x, y):\n","    x = x.reshape(x.shape[0],x.shape[1],x.shape[2],1)\n","    y = utils.to_categorical(y) #8 -> 0 0 0 0 0 0 0 0 1 0\n","    return x, y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bsQTVV1mKJ0N"},"source":["# Redimensionando os espectogramas e labels\n","x_train, y_train = pre_processing_data_to_keras_format(x_train, y_train)\n","x_test, y_test = pre_processing_data_to_keras_format(x_test, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tu38cMpYKJ0W","executionInfo":{"status":"ok","timestamp":1600533078074,"user_tz":180,"elapsed":661,"user":{"displayName":"Maik Fonseca","photoUrl":"","userId":"00360461244938649347"}},"outputId":"4d5b2ea6-9924-43fc-a91e-caadf264c41a","colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["print(x_test.shape)\n","print(y_test.shape)\n","print(x_train.shape)\n","print(y_train.shape)\n","print(y_train[23000])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(4001, 201, 201, 1)\n","(4001, 13)\n","(23211, 201, 201, 1)\n","(23211, 13)\n","[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fdD9vMakKJ0g"},"source":["## The one with the network parameters"]},{"cell_type":"code","metadata":{"id":"NNDR4zZWKJ0j"},"source":["#Parâmetros de modelo\n","dropout_value = 0.5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3pw61JhgKJ0u"},"source":["## The one with the network architecture"]},{"cell_type":"code","metadata":{"id":"tfOq5mRvKJ0v"},"source":["# Inicializando a CNN\n","classifier = Sequential()\n","\n","#Camada de convolução\n","classifier.add(Convolution2D(32, kernel_size=(5,5), input_shape = (201, 201,1), activation = 'relu', padding='same', name = 'conv_1'))\n","\n","#Camada de pooling\n","classifier.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2), padding='same', name = 'pool_1'))\n","\n","#Camada de normalização\n","classifier.add(BatchNormalization())\n","\n","#Segunda camada convolucional\n","classifier.add(Convolution2D(64, kernel_size=(5,5), activation = 'relu', padding='same', name = 'conv_2'))\n","\n","#Segunda camada de pooling\n","classifier.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name = 'pool_2'))\n","\n","#Segunda camada de normalização\n","classifier.add(BatchNormalization())\n","\n","#Terceira camada convolucional\n","classifier.add(Convolution2D(64, kernel_size=(5,5), activation = 'relu', padding='same', name = 'conv_3'))\n","\n","#Terceira camada de pooling\n","classifier.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name = 'pool_3'))\n","\n","#Terceira camada de normalização\n","classifier.add(BatchNormalization())\n","\n","#Quarta camada convolucional\n","classifier.add(Convolution2D(64, kernel_size=(5,5), activation = 'relu', padding='same', name = 'conv_4'))\n","\n","#Quarta camada de pooling\n","classifier.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name = 'pool_4'))\n","\n","#Quarta camada de normalização\n","classifier.add(BatchNormalization())\n","\n","#Vetorizando os mapas de características do último pooling (camada de entrada)\n","classifier.add(Flatten())\n","\n","#Dropout\n","classifier.add(Dropout(dropout_value))\n","\n","#Camada totalmente conectada ou oculta\n","classifier.add(Dense(activation='relu', units=256, name = 'dense_1'))\n","\n","#Dropout\n","classifier.add(Dropout(dropout_value))\n","\n","#Camada de saída\n","classifier.add(Dense(activation='softmax', units=13,  name = 'classification'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7OwZGJOwKJ07","executionInfo":{"status":"ok","timestamp":1600533086070,"user_tz":180,"elapsed":1021,"user":{"displayName":"Maik Fonseca","photoUrl":"","userId":"00360461244938649347"}},"outputId":"569c676d-0dba-4392-b78b-60b80bf76c52","colab":{"base_uri":"https://localhost:8080/","height":746}},"source":["classifier.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv_1 (Conv2D)              (None, 201, 201, 32)      832       \n","_________________________________________________________________\n","pool_1 (MaxPooling2D)        (None, 101, 101, 32)      0         \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 101, 101, 32)      128       \n","_________________________________________________________________\n","conv_2 (Conv2D)              (None, 101, 101, 64)      51264     \n","_________________________________________________________________\n","pool_2 (MaxPooling2D)        (None, 51, 51, 64)        0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 51, 51, 64)        256       \n","_________________________________________________________________\n","conv_3 (Conv2D)              (None, 51, 51, 64)        102464    \n","_________________________________________________________________\n","pool_3 (MaxPooling2D)        (None, 26, 26, 64)        0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 26, 26, 64)        256       \n","_________________________________________________________________\n","conv_4 (Conv2D)              (None, 26, 26, 64)        102464    \n","_________________________________________________________________\n","pool_4 (MaxPooling2D)        (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 13, 13, 64)        256       \n","_________________________________________________________________\n","flatten (Flatten)            (None, 10816)             0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 10816)             0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 256)               2769152   \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","classification (Dense)       (None, 13)                3341      \n","=================================================================\n","Total params: 3,030,413\n","Trainable params: 3,029,965\n","Non-trainable params: 448\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DtwlOhYJKJ1H"},"source":["$Atividade (2.0 pt):$ apresentar um notebook com a arquitetura adaptada para os spectrograms da sua base."]},{"cell_type":"markdown","metadata":{"id":"lWPVTtn3KJ1I"},"source":["# S03 T03: CNN training"]},{"cell_type":"code","metadata":{"id":"HiLfybfrKJ1L"},"source":["from keras.callbacks import ModelCheckpoint\n","from keras import optimizers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J9FqKY2FKJ1V"},"source":["#Parâmetros de treinamento\n","learning_rate = 0.001\n","decay_=0.0001\n","epochs = 5\n","batch_size = 128\n","validation_split=0.1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pyn_d6NZKJ1g"},"source":["#Compilando a CNN: inicializando as variáveis\n","sgd = optimizers.SGD(lr=learning_rate, decay=decay_)\n","classifier.compile(optimizer = 'sgd', loss= 'categorical_crossentropy', metrics=['accuracy'])\n","\n","checkpointBest = ModelCheckpoint('best_aumentation_mel_7.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto', save_freq='epoch') \n","checkpointLast = ModelCheckpoint('last_aumentation_mel_7.h5', monitor='val_loss', verbose=1, save_best_only=False, mode='auto', save_freq='epoch') "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cu8Uahuy7Q6k"},"source":["model = models.load_model(path_save+\"last_aumentation_mel_6.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eQIIDM2QKJ1u","executionInfo":{"status":"ok","timestamp":1600551118524,"user_tz":180,"elapsed":18021815,"user":{"displayName":"Maik Fonseca","photoUrl":"","userId":"00360461244938649347"}},"outputId":"71adc223-177c-4305-e2b4-9b08ba4dda0b","colab":{"base_uri":"https://localhost:8080/","height":575}},"source":["#treinando o modelo\n","model.fit(x_train, y_train, validation_split=validation_split, batch_size=batch_size, epochs=epochs, callbacks=[checkpointBest, checkpointLast], verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","164/164 [==============================] - ETA: 0s - loss: 0.1428 - accuracy: 0.9505 \n","Epoch 00001: val_loss improved from inf to 8.57746, saving model to best_aumentation_mel_7.h5\n","\n","Epoch 00001: saving model to last_aumentation_mel_7.h5\n","164/164 [==============================] - 3670s 22s/step - loss: 0.1428 - accuracy: 0.9505 - val_loss: 8.5775 - val_accuracy: 0.2295\n","Epoch 2/5\n","164/164 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.9538 \n","Epoch 00002: val_loss did not improve from 8.57746\n","\n","Epoch 00002: saving model to last_aumentation_mel_7.h5\n","164/164 [==============================] - 3654s 22s/step - loss: 0.1332 - accuracy: 0.9538 - val_loss: 10.4617 - val_accuracy: 0.2412\n","Epoch 3/5\n","164/164 [==============================] - ETA: 0s - loss: 0.1277 - accuracy: 0.9567 \n","Epoch 00003: val_loss did not improve from 8.57746\n","\n","Epoch 00003: saving model to last_aumentation_mel_7.h5\n","164/164 [==============================] - 3609s 22s/step - loss: 0.1277 - accuracy: 0.9567 - val_loss: 10.5767 - val_accuracy: 0.2244\n","Epoch 4/5\n","164/164 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.9605 \n","Epoch 00004: val_loss did not improve from 8.57746\n","\n","Epoch 00004: saving model to last_aumentation_mel_7.h5\n","164/164 [==============================] - 3595s 22s/step - loss: 0.1152 - accuracy: 0.9605 - val_loss: 10.3901 - val_accuracy: 0.2283\n","Epoch 5/5\n","164/164 [==============================] - ETA: 0s - loss: 0.1155 - accuracy: 0.9611 \n","Epoch 00005: val_loss did not improve from 8.57746\n","\n","Epoch 00005: saving model to last_aumentation_mel_7.h5\n","164/164 [==============================] - 3382s 21s/step - loss: 0.1155 - accuracy: 0.9611 - val_loss: 10.3490 - val_accuracy: 0.2343\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f9b0ccd85f8>"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"v6sdK--5KJ12"},"source":["#Salvando o último modelo \n","model.save(path_save+'best_aumentation_mel_7.h5')\n","model.save(path_save+'last_aumentation_mel_7.h5')"],"execution_count":null,"outputs":[]}]}